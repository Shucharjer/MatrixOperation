## 以矩阵乘法为例的循环优化

==注意：由于现代编译器的优化较好，在实际运行中，直接使用下列优化后的代码的运行效果不一定比未手动优化时的运行效果好，有时候会更差。下列代码仅考虑编译器没有优化的情况！同时也有可能存在过渡优化现象，不保证优化后的结果在编译器没有优化的情况下，运行的速度就更快。==

另：可以使用#pragma关掉优化

*实测最后还是比较快的*  
$$
C_{ij} = \Sigma^n_{k=1} A_{ik} \times B_{kj}
$$

### 未优化时

```c++
void MatrixOperation::Cross(double* dst, double* src1, double* src2, int rowsOfsrc1, int colsOfsrc2, int colsOfsrc1)
{
    for (int i = 0; i < rowsOfsrc1; i++) {
		for (int j = 0; j < colsOfsrc2; j++) {
            *(dst + i * colsOfsrc2 + j) = 0; // 初始化矩阵
			for (int k = 0; k < colsOfsrc1; k++) {
                *(dst + i * colsOfsrc2 + j) += *(src1 + i * colsOfsrc2 + k) * *(src2 + k * colsOfsrc2 + j);
            }
        }
    }
    return;
}
```

### 循环分布

显然，初始化矩阵的语句可以使用循环分布，增加并行性。  

```c++
void MatrixOperation::Cross(double* dst, double* src1, double* src2, int rowsOfsrc1, int colsOfsrc2, int colsOfsrc1)
{
	for (int i = 0; i < rowsOfsrc1; i++)
		for (int j = 0; j < rowsOfsrc1; j++)
			*(dst + i * colsOfsrc2 + j) = 0;

	for (int i = 0; i < rowsOfsrc1; i++)
		for (int j = 0; j < colsOfsrc2; j++)
			for (int k = 0; k < colsOfsrc1; k++)
				*(dst + i * colsOfsrc2 + j) += *(src1 + i * colsOfsrc2 + k) * *(src2 + k * colsOfsrc2 + j);
	return;
}
```

### 循环交换

访问同一行比访问同一列快，则应当访问B的一列后，保持访问这一列的前提不变，访问A中的不同行

```c++
void MatrixOperation::Cross(double* dst, double* src1, double* src2, int rowsOfsrc1, int colsOfsrc2, int colsOfsrc1)
{
	for (int i = 0; i < rowsOfsrc1; i++)
		for (int j = 0; j < rowsOfsrc1; j++)
			*(dst + i * colsOfsrc2 + j) = 0;

	for (int i = 0; i < rowsOfsrc1; i++)
		for (int k = 0; k < colsOfsrc1; k++)
			for (int j = 0; j < colsOfsrc2; j++)
				*(dst + i * colsOfsrc2 + j) += *(src1 + i * colsOfsrc2 + k) * *(src2 + k * colsOfsrc2 + j);
	return;
}
```

### 循环分块

在此之前先引入一个函数  

```c++
int MatrixOperation::Min(int num1, int num2) {
	return num1 <= num2 ? num1 : num2;
}
```

其中`S`为一静态量，块的大小  

#### 第一次

每一次都是为了保证更高的cache命中率。  

```c++
void MatrixOperation::Cross(double* dst, double* src1, double* src2, int rowsOfsrc1, int colsOfsrc2, int colsOfsrc1)
{
	for (int i = 0; i < rowsOfsrc1; i++)
		for (int j = 0; j < rowsOfsrc1; j++)
			*(dst + i * colsOfsrc2 + j) = 0;
    
    for (int i = 0; i < rowsOfsrc1; i++)
		for (int k = 0; k < colsOfsrc1; k++)
			for (int j = 0; j < colsOfsrc2; j += S)
				for (int I = i; J < Min(i + S, rowsOfsrc1); I++)
					*(dst + I * colsOfsrc2 + j) += *(src1 + I * colsOfsrc2 + k) * *(src2 + k * colsOfsrc2 + j);
    return;
}
```

#### 第二次

访问A中的行时，应尽量保证访问完当前行后，下一行依旧在缓存中

```c++
void MatrixOperation::Cross(double* dst, double* src1, double* src2, int rowsOfsrc1, int colsOfsrc2, int colsOfsrc1)
{
	for (int i = 0; i < rowsOfsrc1; i++)
		for (int j = 0; j < rowsOfsrc1; j++)
			*(dst + i * colsOfsrc2 + j) = 0;
	
	for (int i = 0; i < rowsOfsrc1; i++)
		for (int k = 0; k < colsOfsrc1; k++)
			for (int j = 0; j < colsOfsrc2; j += S)
				for (int I = i; J < Min(i + S, rowsOfsrc1); I++)
                    for (int K = k; K < Min(k + S, colsOfsrc1); K++)
						*(dst + I * colsOfsrc2 + j) += *(src1 + I * colsOfsrc2 + K) * *(src2 + K * colsOfsrc2 + j);
	return;
}
```

#### 第三次

访问完B中的列时，应尽量保证访问完当前列后，下一列依旧在缓存中

```c++
void MatrixOperation::Cross(double* dst, double* src1, double* src2, int rowsOfsrc1, int colsOfsrc2, int colsOfsrc1)
{
	for (int i = 0; i < rowsOfsrc1; i++)
		for (int j = 0; j < rowsOfsrc1; j++)
			*(dst + i * colsOfsrc2 + j) = 0;
	
	for (int i = 0; i < rowsOfsrc1; i++)
		for (int k = 0; k < colsOfsrc1; k++)
			for (int j = 0; j < colsOfsrc2; j += S)
				for (int I = i; J < Min(i + S, rowsOfsrc1); I++)
                    for (int K = k; K < Min(k + S, colsOfsrc1); K++)
                        for (int J = j; J < Min(j + S, colsOfsrc2); J++)
							*(dst + I * colsOfsrc2 + J) += *(src1 + I * colsOfsrc2 + K) * *(src2 + K * colsOfsrc2 + J);
	return;
}
```

### 循环展开

当下的编译器可能会自动尝试展开循环，或者使用#pragma调整相关设置，#pragma相关的参数很多，可以根据具体情况使用。  

```c++
void MatrixOperation::Cross(double* dst, double* src1, double* src2, int rowsOfsrc1, int colsOfsrc2, int colsOfsrc1)
{
#pragma omp parallel for simd
	for (int i = 0; i < rowsOfsrc1; i++)
		for (int j = 0; j < rowsOfsrc1; j++)
			*(dst + i * colsOfsrc2 + j) = 0;

	for (int i = 0; i < rowsOfsrc1; i++)
		for (int k = 0; k < colsOfsrc1; k++)
			for (int j = 0; j < colsOfsrc2; j++)
				for (int I = i; i < Min(rowsOfsrc1, i + BlockSize); i++)
					for (int K = k; K < Min(rowsOfsrc1, k + BlockSize); K++)
#pragma omp parallel for simd
						for (int J = j; J < Min(colsOfsrc2, j + BlockSize); J++)
							*(dst + I * colsOfsrc2 + J) += *(src1 + I * colsOfsrc2 + K) * *(src2 + K * colsOfsrc2 + J);
	return;
}
```